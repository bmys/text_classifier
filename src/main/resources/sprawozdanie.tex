\documentclass{classrep}
\usepackage[utf8]{inputenc}
\usepackage{color}

\studycycle{Informatyka, studia zaoczne, I st.}
\coursesemester{VI}

\coursename{Komputerowe systemy rozpoznawania}
\courseyear{2018/2019}

\courseteacher{dr hab. inż. Adam Niewiadomski profesor PŁ
}
\coursegroup{niedziela, 12:00}

\author{
  \studentinfo{Bartosz Myśliwiec}{211827} \and
  \studentinfo{Mateusz Misiak}{211967} \and
}

\title{Zadanie 1:  Ekstrakcja cech, miary podobieństwa, klasyfikacja.}
\svnurl{https://github.com/bmys/text_classifier}

\begin{document}
\maketitle

\section{Cel}

Celem zadania było zaprojektowanie i stworzenie programu komputerowego zdolnego do klasyfikacji 
rzeczywistych obiektow przy użyciu metod komputerowego rozpoznawania takich jak ekstrakcja cech oraz algorytm KNN, a następnie przetestowanie wpływu parametrów algorytmu na efektywność klasyfikacji.


\section{Wprowadzenie}
Komputerowe systemy rozpoznawania są to systemy które posiadają sztuczną inteligencję, która ma odwzorować prawdziwą inteligencję ludzi w danej dziedzinie. 
System taki jest zdolny wykonywać czynności tak samo jak człowiek — ekspert.


W celu realizacji rozpoznawania rzeczywistych obiektów przez komputer, konieczne jest przedstawienie ich reprezentacji w sposób zrozumiały dla maszyny, czyli matematycznego odzwierciedlenia cech jako indeksowaną listę atrybutów — obraz.


Uzyskanie obrazu jest możliwe dzięki ekstraktorom cech czyli funkcją które przekształcają swoje argumenty na wynik danej cechy możliwy do poddania dalszej analizie.


Problemem w tym zadaniu może okazać się zbyt duża wielkość wektora cech, dlatego konieczne jest wstępne przetworzenie danych, na które składa się usunięcie danych zawierających szczątkową informację przydatną do klasyfikacji oraz ujednolicenie cech o podobnym znaczeniu w celu redukcji rozmiaru wektora cech.


By to osiągnąć usunęliśmy z wejściowego wektora słów, słowa z stop-list czyli listy słów pojawiających się często w mowie potocznej, które nie służą do przekazywania informacji.
Usunelismy również znaki przystankowe, cyfry oraz zamieniliśmy wszystkie litery na małe.


By ujednolicić słowa o podobnym znaczeniu zastosowaliśmy „stemowanie” czyli proces polegający na obcięciu z wyrazów końcówek fleksyjnych i wyodrębnienie w ten sposób rdzeń słowa.


Cechy jakie wykorzystaliśmy do realizacji zadania mają charakter nieparametryczny, czyli do wyznaczania wartości danej cechy nie korzystamy z wiedzy na temat rozkładu danej zmiennej w zbiorze.


Stworzone przez nas cechy posiadają również charakter uniwersalny ponieważ nie bazują na właściwościach specyficznych dla danej etykiety a wykorzystują ogólne cechy dotyczące tekstów, a generowanie słów kluczowych odbywa się w sposób automatyczny.


Zbiór dokumentów podzieliliśmy na dwa podzbiory:
- zbiór uczący wykorzystywany do wygenerowania słów kluczowych oraz zapewnienia wstępnych przypadków dla algorytmu KNN "Zimny start". Oznaczany w sprawozdaniu jako L stanowiący 60\% zbioru początkowego


-zbiór testowy służący w celu weryfikacji zdolności uogólniających modelu. Oznaczamy jako T

Algorytm KNN jest to algorytm który dokonuje kwalifikacji na podstawie podobieństwa wektorów cech, przypadku klasyfikowanego oraz skwalifikowanych już wcześniej obiektów.
Podobieństwo wektora cech uzyskiwane jest za pomocą metryki, która wyznacza odległość pomiędzy wektorami cech.
Najliczniejsza etykieta sposród K elementów o najmniejszym wyniku metryki decyduje o klasie którą przydzielimy elementowi klasyfikowanemu.


W naszym rozwiązaniu problemu klasyfikacji zbioru artykułów prasowych ze zbioru „reuters 21578” względem ich etykiet lokalizacji zaimplementowaliśmy następujące ekstraktory cech:
\subsubsection{Ekstraktory cech}
\begin{enumerate}
  \item Średnia pozycja słów kluczowych od środka dokumentu.

  \item Pierwsze słowo w dokumencie
  \item Ważona pozycja słowa kluczowego w dokumencie
   \item Najczęściej występujące dwuliterowe podciągi w dokumencie
reprezentowane jako słowo zbudowane z tych podciągów według liczności ich występowania.

  \item Stosunek ilości słów kluczowych występujących w pierwszej i czwartej ćwiartce słów w dokumencie do ilości słów kluczowych występujących w drugiej i trzeciej ćwiartce słów w dokumencie.
  
    \item Stosunek ilości unikalnych słów do ilości słów w dokumencie
\end{enumerate}




\subsubsection{Metryki}
W celu oceny podobieństwa wektorów cech użyliśmy następujących metryk:

Metryka Euklidesowa:
$${\sqrt {\sum _{i=1}^{n}(x_{i}-y_{i})^{2}}}$$

Metryka Czebyszewa:
$$\max _{i}|x_{i}-y_{i}|$$


Metryka taksówkowa:
$$\sum _{i=1}^{n}|x_{i}-y_{i}|$$


\section{Wyniki}

\subsection{Porównanie wpływu parametru k na klasyfikacje}
Wszystkie cechy, k = 2, metryka: euklidesowa, słów kluczowych na klasę: 30\newline

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 X  & japan & west-germany & canada & usa & france & uk\\
\hline
japan & 56 & 2 & 12 & 138 & 3 & 7\\
\hline
west-germany & 33 & 7 & 11 & 66 & 5 & 11\\
\hline
canada & 23 & 1 & 32 & 254 & 3 & 4\\
\hline
usa & 221 & 11 & 286 & 3791 & 14 & 18\\
\hline
france & 13 & 0 & 4 & 67 & 7 & 4\\
\hline
uk & 31 & 4 & 33 & 207 & 9 & 21\\
\hline
\end{tabular}
\caption{Macierz pomyłek}\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Etykieta & Wynik klasyfikacji & procent\\
\hline
japan & 56 / 218 & 25,69\%\\
\hline
west-germany & 7 / 133 & 5,26\%\\
\hline
canada & 32 / 317 & 10,09\%\\
\hline
usa & 3791 / 4341 & 87,33\%\\
\hline
france & 7 / 95 & 7,37\%\\
\hline
uk & 21 / 305 & 6,89\%\\
\hline
wszystkie & 3914,00 / 5409 & 72,36\%\\
\hline
\end{tabular}
\caption{Ilość poprawnie skwalifikowanych}\end{table}





\newpage
Wszystkie cechy, k = 5, metryka: euklidesowa, słów kluczowych na klasę: 30\newline


\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 X  & japan & west-germany & canada & usa & france & uk\\
\hline
japan & 46 & 17 & 27 & 89 & 22 & 17\\
\hline
west-germany & 32 & 13 & 6 & 60 & 18 & 4\\
\hline
canada & 34 & 30 & 87 & 145 & 15 & 6\\
\hline
usa & 232 & 279 & 1483 & 2167 & 97 & 83\\
\hline
france & 11 & 15 & 5 & 45 & 17 & 2\\
\hline
uk & 24 & 52 & 26 & 143 & 25 & 35\\
\hline
\end{tabular}
\caption{Macierz pomyłek}\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Etykieta & Wynik klasyfikacji & procent\\
\hline
japan & 46 / 218 & 21,10\%\\
\hline
west-germany & 13 / 133 & 9,77\%\\
\hline
canada & 87 / 317 & 27,44\%\\
\hline
usa & 2167 / 4341 & 49,92\%\\
\hline
france & 17 / 95 & 17,89\%\\
\hline
uk & 35 / 305 & 11,48\%\\
\hline
wszystkie & 2365,00 / 5409 & 43,72\%\\
\hline
\end{tabular}
\caption{Ilość poprawnie skwalifikowanych}\end{table}

















Wszystkie cechy, k = 10, metryka: euklidesowa, słów kluczowych na klasę: 30\newline

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 X  & japan & west-germany & canada & usa & france & uk\\
\hline
japan & 54 & 15 & 17 & 64 & 29 & 39\\
\hline
west-germany & 32 & 16 & 7 & 40 & 23 & 15\\
\hline
canada & 31 & 33 & 64 & 140 & 12 & 37\\
\hline
usa & 279 & 264 & 1134 & 2307 & 114 & 243\\
\hline
france & 16 & 12 & 5 & 30 & 16 & 16\\
\hline
uk & 29 & 46 & 32 & 107 & 24 & 67\\
\hline
\end{tabular}
\caption{Macierz pomyłek}\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Etykieta & Wynik klasyfikacji & procent\\
\hline
japan & 54 / 218 & 24,77\%\\
\hline
west-germany & 16 / 133 & 12,03\%\\
\hline
canada & 64 / 317 & 20,19\%\\
\hline
usa & 2307 / 4341 & 53,14\%\\
\hline
france & 16 / 95 & 16,84\%\\
\hline
uk & 67 / 305 & 21,97\%\\
\hline
wszystkie & 2524,00 / 5409 & 46,66\%\\
\hline
\end{tabular}
\caption{Ilość poprawnie skwalifikowanych}
\end{table}





\newpage
Wszystkie cechy, k = 20, metryka: euklidesowa, słów kluczowych na klasę: 30\newline

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 X  & japan & west-germany & canada & usa & france & uk\\
\hline
japan & 44 & 42 & 8 & 41 & 1 & 82\\
\hline
west-germany & 31 & 36 & 1 & 16 & 0 & 49\\
\hline
canada & 26 & 45 & 18 & 119 & 0 & 109\\
\hline
usa & 216 & 399 & 345 & 2260 & 2 & 1119\\
\hline
france & 16 & 17 & 1 & 17 & 3 & 41\\
\hline
uk & 27 & 63 & 5 & 61 & 1 & 148\\
\hline
\end{tabular}
\caption{Macierz pomyłek}\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Etykieta & Wynik klasyfikacji & procent\\
\hline
japan & 44 / 218 & 20,18\%\\
\hline
west-germany & 36 / 133 & 27,07\%\\
\hline
canada & 18 / 317 & 5,68\%\\
\hline
usa & 2260 / 4341 & 52,06\%\\
\hline
france & 3 / 95 & 3,16\%\\
\hline
uk & 148 / 305 & 48,52\%\\
\hline
wszystkie & 2509,00 / 5409 & 46,39\%\\
\hline
\end{tabular}
\caption{Ilość poprawnie skwalifikowanych}\end{table}



\newpage
Wszystkie cechy, k = 30, metryka: euklidesowa, słów kluczowych na klasę: 30\newline
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 X  & japan & west-germany & canada & usa & france & uk\\
\hline
japan & 17 & 68 & 0 & 49 & 0 & 84\\
\hline
west-germany & 6 & 61 & 0 & 14 & 0 & 52\\
\hline
canada & 6 & 64 & 0 & 128 & 1 & 118\\
\hline
usa & 44 & 576 & 2 & 2419 & 1 & 1299\\
\hline
france & 4 & 28 & 0 & 17 & 2 & 44\\
\hline
uk & 5 & 85 & 0 & 60 & 1 & 154\\
\hline
\end{tabular}
\caption{Macierz pomyłek}\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Etykieta & Wynik klasyfikacji & procent\\
\hline
japan & 17 / 218 & 7,80\%\\
\hline
west-germany & 61 / 133 & 45,86\%\\
\hline
canada & 0 / 317 & 0\%\\
\hline
usa & 2419 / 4341 & 55,72\%\\
\hline
france & 2 / 95 & 2,11\%\\
\hline
uk & 154 / 305 & 50,49\%\\
\hline
wszystkie & 2653,00 / 5409 & 49,05\%\\
\hline
\end{tabular}
\caption{Ilość poprawnie skwalifikowanych}\end{table}



\newpage
\subsection{Porównanie wpływu metryki na klasyfikacje}

\subsubsection{Wszystkie cechy, k = 8, metryka: euklidesowa, słów kluczowych na klasę: 30}
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 X  & japan & west-germany & canada & usa & france & uk\\
\hline
japan & 61 & 22 & 23 & 90 & 11 & 11\\
\hline
west-germany & 36 & 21 & 11 & 51 & 10 & 4\\
\hline
canada & 34 & 35 & 79 & 152 & 7 & 10\\
\hline
usa & 303 & 298 & 1343 & 2266 & 71 & 60\\
\hline
france & 16 & 17 & 5 & 42 & 11 & 4\\
\hline
uk & 32 & 54 & 47 & 123 & 16 & 33\\
\hline
\end{tabular}
\caption{Macierz pomyłek}\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Etykieta & Wynik klasyfikacji & procent\\
\hline
japan & 61 / 218 & 27,98\%\\
\hline
west-germany & 21 / 133 & 15,79\%\\
\hline
canada & 79 / 317 & 24,92\%\\
\hline
usa & 2266 / 4341 & 52,20\%\\
\hline
france & 11 / 95 & 11,58\%\\
\hline
uk & 33 / 305 & 10,82\%\\
\hline
wszystkie & 2471,00 / 5409 & 45,68\%\\
\hline
\end{tabular}
\caption{Ilość poprawnie skwalifikowanych}\end{table}
\newpage
\subsubsection{Wszystkie cechy, k = 8, metryka: czebyszewa, słów kluczowych na klasę: 30}
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 X  & japan & west-germany & canada & usa & france & uk\\
\hline
japan & 58 & 29 & 21 & 87 & 21 & 2\\
\hline
west-germany & 39 & 14 & 11 & 51 & 17 & 1\\
\hline
canada & 43 & 24 & 57 & 179 & 10 & 4\\
\hline
usa & 377 & 180 & 886 & 2760 & 94 & 44\\
\hline
france & 21 & 16 & 5 & 48 & 4 & 1\\
\hline
uk & 49 & 31 & 51 & 143 & 24 & 7\\
\hline
\end{tabular}
\caption{Macierz pomyłek}\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Etykieta & Wynik klasyfikacji & procent\\
\hline
japan & 58 / 218 & 26,61\%\\
\hline
west-germany & 14 / 133 & 10,53\%\\
\hline
canada & 57 / 317 & 17,98\%\\
\hline
usa & 2760 / 4341 & 63,58\%\\
\hline
france & 4 / 95 & 4,21\%\\
\hline
uk & 7 / 305 & 2,30\%\\
\hline
wszystkie & 2900,00 / 5409 & 53,61\%\\
\hline
\end{tabular}
\caption{Ilość poprawnie skwalifikowanych}\end{table}



\newpage
\subsubsection{Wszystkie cechy, k = 8, metryka: uliczna, słów kluczowych na klasę: 30}
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 X  & japan & west-germany & canada & usa & france & uk\\
\hline
japan & 45 & 30 & 21 & 31 & 25 & 66\\
\hline
west-germany & 35 & 10 & 10 & 17 & 24 & 37\\
\hline
canada & 30 & 37 & 106 & 69 & 11 & 64\\
\hline
usa & 274 & 274 & 1683 & 1419 & 98 & 593\\
\hline
france & 14 & 14 & 4 & 15 & 16 & 32\\
\hline
uk & 34 & 46 & 57 & 40 & 22 & 106\\
\hline
\end{tabular}
\caption{Macierz pomyłek}\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Etykieta & Wynik klasyfikacji & procent\\
\hline
japan & 45 / 218 & 20,64\%\\
\hline
west-germany & 10 / 133 & 7,52\%\\
\hline
canada & 106 / 317 & 33,44\%\\
\hline
usa & 1419 / 4341 & 32,69\%\\
\hline
france & 16 / 95 & 16,84\%\\
\hline
uk & 106 / 305 & 34,75\%\\
\hline
wszystkie & 1702,00 / 5409 & 31,47\%\\
\hline
\end{tabular}
\caption{Ilość poprawnie skwalifikowanych}\end{table}



\end{document}
